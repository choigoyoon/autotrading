import pandas as pd
import numpy as np
from pathlib import Path
import sys
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings

# --- í”„ë¡œì íŠ¸ ì„¤ì • ---
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

from tools.optimize_hybrid_system import get_base_signals, OptimizationConfig as BaseConfig
from tools.backtest_ai_model import run_backtest as run_simple_backtest

warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# --- í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì„¤ì • ---
class PortfolioConfig(BaseConfig):
    OUTPUT_DIR = project_root / "results" / "portfolio_optimization"
    # ì¼ˆë¦¬ ê³µì‹ ìµœëŒ€ ë² íŒ… ë¹„ìœ¨ (íŒŒì‚° ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „ì¥ì¹˜)
    KELLY_MAX_FRACTION = 0.5 

# --- ìƒˆë¡œìš´ ë°±í…ŒìŠ¤íŒ… ì—”ì§„ ---
def backtest_with_dynamic_sizing(prices: pd.Series, target_exposure: pd.Series, config: PortfolioConfig):
    """
    ë™ì  í¬ì§€ì…˜ ì‚¬ì´ì§•ì„ ë°˜ì˜í•˜ëŠ” ë²¡í„°í™”ëœ ë°±í…ŒìŠ¤íŒ… ì—”ì§„.
    target_exposure: í¬íŠ¸í´ë¦¬ì˜¤ì˜ ëª©í‘œ ë…¸ì¶œ ìˆ˜ì¤€ (-1.0 ~ 1.0)
    """
    # ë°±í…ŒìŠ¤íŒ…ì„ ìœ„í•´ ë°ì´í„° ì •ë ¬
    data = pd.DataFrame({'price': prices, 'exposure': target_exposure}).dropna()
    prices = data['price']
    target_exposure = data['exposure']

    # ì‹¤ì œ í¬ì§€ì…˜ì€ ì‹ í˜¸ ë°œìƒ ë‹¤ìŒ ìº”ë“¤ë¶€í„° ì ìš©
    actual_exposure = target_exposure.shift(1).fillna(0)
    
    # ë¡œê·¸ ìˆ˜ìµë¥  ê³„ì‚°
    log_returns = np.log(prices / prices.shift(1)).fillna(0)
    
    # ì „ëµì˜ ë¡œê·¸ ìˆ˜ìµë¥ 
    strategy_log_returns = actual_exposure * log_returns
    
    # ê±°ë˜ ë¹„ìš© ê³„ì‚° (ë…¸ì¶œë„ ë³€í™”ëŸ‰ì— ë¹„ë¡€)
    exposure_changes = actual_exposure.diff().fillna(0).abs()
    costs = exposure_changes * config.FEE
    
    # ë¹„ìš©ì„ ì°¨ê°í•œ ìˆœìˆ˜ìµë¥ 
    net_strategy_log_returns = strategy_log_returns - costs
    
    # ëˆ„ì  ìˆ˜ìµë¥  ë° ìì‚° ê³¡ì„ 
    cumulative_log_returns = net_strategy_log_returns.cumsum()
    equity_curve = config.INITIAL_CAPITAL * np.exp(cumulative_log_returns)

    # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    total_return = (equity_curve.iloc[-1] / config.INITIAL_CAPITAL) - 1
    
    running_max = equity_curve.cummax()
    drawdown = (equity_curve - running_max) / running_max
    mdd = drawdown.min()
    
    annualization_factor = np.sqrt(365 * 24 * 60) # 1ë¶„ë´‰ ê¸°ì¤€
    sharpe_ratio = net_strategy_log_returns.mean() / net_strategy_log_returns.std() * annualization_factor if net_strategy_log_returns.std() != 0 else 0
    
    # ê±°ë˜ íšŸìˆ˜ëŠ” ë…¸ì¶œì´ 0ì´ ì•„ë‹ˆì—ˆë˜ ê¸°ê°„ìœ¼ë¡œ ê³„ì‚°
    total_trades = (exposure_changes > 0).sum()
    
    return {
        "Total Return (%)": total_return * 100,
        "MDD (%)": mdd * 100,
        "Sharpe Ratio": sharpe_ratio,
        "Trades": total_trades,
        "Final Equity": equity_curve.iloc[-1],
    }, equity_curve

# --- í¬ì§€ì…˜ ì‚¬ì´ì§• ì „ëµ í•¨ìˆ˜ ---

def get_rule_based_exposure(signals_df: pd.DataFrame) -> pd.Series:
    """ì‚¬ìš©ìê°€ ì •ì˜í•œ ê·œì¹™ì— ë”°ë¼ í¬ì§€ì…˜ í¬ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    def sizing_rule(row):
        ai_signal = row['ai_signal']
        macd_signal = row['macd_signal']
        confidence = row['ai_confidence']
        
        # í•©ì˜ ì‹ í˜¸
        if ai_signal == macd_signal:
            if confidence >= 0.95: return ai_signal * 0.30
            if confidence >= 0.85: return ai_signal * 0.20
            if confidence >= 0.75: return ai_signal * 0.10
        # AI ë‹¨ë… ì‹ í˜¸
        elif confidence >= 0.80:
            return ai_signal * 0.05
        # ì‹ í˜¸ ì¶©ëŒ ë˜ëŠ” ë‚®ì€ ì‹ ë¢°ë„
        return 0.0
        
    return signals_df.apply(sizing_rule, axis=1)

def get_kelly_exposure(signals_df: pd.DataFrame, config: PortfolioConfig) -> pd.Series:
    """ì¼ˆë¦¬ ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ í¬ì§€ì…˜ í¬ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    print("\n--- ì¼ˆë¦¬ ê³µì‹ ê³„ì‚°ì„ ìœ„í•œ ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ---")
    # 'Consensus (Strict)' ì „ëµì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¹ë¥ /ì†ìµë¹„ ê³„ì‚°
    consensus_signals = signals_df.apply(lambda r: r['ai_signal'] if r['ai_signal'] == r['macd_signal'] else 0, axis=1)
    
    # ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŠ¸ë¡œ ê±°ë˜ë³„ ìˆ˜ìµë¥  í™•ë³´
    _, equity_curve = run_simple_backtest(consensus_signals, signals_df['price'], config)
    trades = consensus_signals.diff().fillna(0).abs()
    trade_returns = equity_curve.pct_change()[trades != 0]

    if trade_returns.empty or trade_returns.std() == 0:
        print("ê²½ê³ : ì¼ˆë¦¬ ê³µì‹ ê³„ì‚°ì„ ìœ„í•œ ê±°ë˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¼ˆë¦¬ ì „ëµì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return pd.Series(0, index=signals_df.index)

    win_rate = (trade_returns > 0).mean()
    
    avg_win = trade_returns[trade_returns > 0].mean()
    avg_loss = abs(trade_returns[trade_returns < 0].mean())
    payoff_ratio = avg_win / avg_loss if avg_loss > 0 else 1.0

    if win_rate == 1.0: # 100% ìŠ¹ë¥ ì´ë©´ ìµœëŒ€ì¹˜ ì‚¬ìš©
        kelly_fraction = config.KELLY_MAX_FRACTION
    else:
        kelly_fraction = win_rate - ((1 - win_rate) / payoff_ratio)

    print(f"  - ìŠ¹ë¥  (p): {win_rate:.2%}")
    print(f"  - ì†ìµë¹„ (b): {payoff_ratio:.2f}")
    print(f"  - ê³„ì‚°ëœ ì¼ˆë¦¬ ë¹„ìœ¨: {kelly_fraction:.2f}")

    # íŒŒì‚° ë°©ì§€ë¥¼ ìœ„í•´ ìµœëŒ€ê°’ ì œí•œ
    final_kelly_fraction = max(0, min(kelly_fraction, config.KELLY_MAX_FRACTION))
    print(f"  - ì ìš©ë  ì¼ˆë¦¬ ë¹„ìœ¨ (ìµœëŒ€ {config.KELLY_MAX_FRACTION:.0%}): {final_kelly_fraction:.2f}")

    # ì¼ˆë¦¬ ë¹„ìœ¨ì„ ëª¨ë“  í•©ì˜ ì‹ í˜¸ì— ì ìš©
    return consensus_signals.apply(lambda x: x * final_kelly_fraction)

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---

def main():
    config = PortfolioConfig()
    config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # 1. AI ë° MACD ê¸°ë³¸ ì‹ í˜¸ ìƒì„±
    base_signals_df = get_base_signals(config)
    if base_signals_df.empty:
        return

    # 2. í¬ì§€ì…˜ ì‚¬ì´ì§• ì „ëµë³„ ëª©í‘œ ë…¸ì¶œ ê³„ì‚°
    exposures = {
        "Rule-Based Sizing": get_rule_based_exposure(base_signals_df),
        "Kelly Criterion Sizing": get_kelly_exposure(base_signals_df, config),
        "Fixed Sizing (Consensus)": base_signals_df.apply(lambda r: r['ai_signal'] if r['ai_signal'] == r['macd_signal'] else 0, axis=1)
    }

    # 3. ì „ëµë³„ í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ…
    all_results = {}
    equity_curves = {}
    print("\n--- ë™ì  í¬ì§€ì…”ë‹ í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ---")
    for name, exposure in tqdm(exposures.items(), desc="í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ… ì¤‘"):
        results, equity = backtest_with_dynamic_sizing(base_signals_df['price'], exposure, config)
        all_results[name] = results
        equity_curves[name] = equity

    # 4. ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥
    print("\n--- í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê²°ê³¼ ---")
    report = pd.DataFrame(all_results).T.sort_values(by="Sharpe Ratio", ascending=False)
    report_path = config.OUTPUT_DIR / "portfolio_performance_report.csv"
    report.to_csv(report_path)
    
    print(f"âœ… í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}")
    print(report)

    # 5. ì‹œê°í™”
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(16, 9))
    
    for name, equity in equity_curves.items():
        perf = all_results[name]
        label = f"{name} (Return: {perf['Total Return (%)']:.2f}%, Sharpe: {perf['Sharpe Ratio']:.2f})"
        ax.plot(equity.index, equity.values, label=label, lw=2)

    ax.set_title('Portfolio Performance by Position Sizing Strategy', fontsize=18, weight='bold')
    ax.set_xlabel('Date')
    ax.set_ylabel('Portfolio Equity')
    ax.legend()
    ax.grid(True)
    
    plot_path = config.OUTPUT_DIR / 'portfolio_equity_curves.png'
    plt.savefig(plot_path, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ… í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµ ê³¡ì„  ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {plot_path}")
    print("\nğŸ‰ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ë¶„ì„ ì™„ë£Œ.")

if __name__ == '__main__':
    main() 