import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import numba
from concurrent.futures import ProcessPoolExecutor, as_completed
import os

# ğŸ”¥ í•µì‹¬: numba parallel=Trueë¡œ CPU í™œìš©ë¥  ê·¹ëŒ€í™”
@numba.njit(parallel=True, fastmath=True)
def analyze_labels(label_timestamps, label_prices, label_types, 
                   ohlcv_timestamps, ohlcv_high, ohlcv_low):
    """CPU ë³‘ë ¬ ìµœì í™”ëœ í•µì‹¬ í•¨ìˆ˜"""
    num_labels = len(label_timestamps)
    results = np.zeros((num_labels, 3), dtype=np.float64)
    
    # ğŸ”¥ numba.prange = ëª¨ë“  CPU ì½”ì–´ í™œìš©!
    for i in numba.prange(num_labels):
        label_ts = label_timestamps[i]
        label_price = label_prices[i]
        label_type = label_types[i]
        
        start_idx = np.searchsorted(ohlcv_timestamps, label_ts)
        
        if start_idx >= len(ohlcv_high):
            continue
            
        if label_type == 1:  # ë§¤ìˆ˜
            max_price = np.max(ohlcv_high[start_idx:])
            profit_pct = ((max_price - label_price) / label_price) * 100
        else:  # ë§¤ë„
            min_price = np.min(ohlcv_low[start_idx:])
            profit_pct = ((label_price - min_price) / label_price) * 100
            
        results[i, 0] = label_ts
        results[i, 1] = profit_pct
        results[i, 2] = label_type
        
    return results

def process_chunk(args):
    """ì²­í¬ ì²˜ë¦¬ (ë‹¨ìˆœí™”)"""
    chunk_id, timeframe, chunk_df, ohlcv_timestamps, ohlcv_high, ohlcv_low = args
    
    try:
        # ë°ì´í„° ì¤€ë¹„
        label_timestamps = chunk_df.index.view('int64')
        label_prices = chunk_df['close'].values.astype(np.float64)
        label_types = chunk_df['label'].values.astype(np.int64)
        
        # ë¶„ì„ ì‹¤í–‰ (ë‚´ë¶€ì ìœ¼ë¡œ ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©)
        results = analyze_labels(label_timestamps, label_prices, label_types,
                               ohlcv_timestamps, ohlcv_high, ohlcv_low)
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(results, columns=['timestamp', 'profit_pct', 'label_type'])
        df['timeframe'] = timeframe
        df['entry_time'] = pd.to_datetime(df['timestamp'])
        
        return df
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜] {timeframe}_ì²­í¬{chunk_id}: {e}")
        return None

def main():
    """ì´ˆê°„ë‹¨ ë©”ì¸ í•¨ìˆ˜"""
    # ğŸ”¥ CPU ì½”ì–´ ìµœëŒ€ í™œìš© ì„¤ì •
    os.environ['NUMBA_NUM_THREADS'] = str(os.cpu_count())
    
    # ê²½ë¡œ ì„¤ì •
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    labels_file = PROJECT_ROOT / 'data' / 'labels_macd' / 'btc_usdt_kst' / 'btc_usdt_kst_merged_labels.parquet'
    ohlcv_dir = PROJECT_ROOT / 'data' / 'processed' / 'btc_usdt_kst' / 'resampled_ohlcv'
    output_file = PROJECT_ROOT / 'results' / 'label_performance' / 'performance_simple_fast.csv'
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"CPU ì½”ì–´ ìˆ˜: {os.cpu_count()}")
    
    # ë°ì´í„° ë¡œë“œ
    print("1. ë°ì´í„° ë¡œë“œ ì¤‘...")
    signals_df = pd.read_parquet(labels_file)
    print(f"   ì´ {len(signals_df):,}ê°œ ë¼ë²¨")
    
    # OHLCV ë¡œë“œ
    print("2. OHLCV ë¡œë“œ ì¤‘...")
    TF_MAP = {
        '1D': '1day', '2D': '2day', '3D': '3day', '1W': '1week',
        '1h': '1h', '2h': '2h', '4h': '4h', '6h': '6h', '8h': '8h', '12h': '12h',
        '1min': '1min', '3min': '3min', '5min': '5min', '10min': '10min', 
        '15min': '15min', '30min': '30min'
    }
    
    ohlcv_data = {}
    for tf in signals_df['timeframe'].unique():
        file_name = TF_MAP.get(tf, tf)
        ohlcv_file = ohlcv_dir / f"{file_name}.parquet"
        if ohlcv_file.exists():
            ohlcv_df = pd.read_parquet(ohlcv_file)
            ohlcv_data[tf] = {
                'timestamps': ohlcv_df.index.view('int64'),
                'high': ohlcv_df['high'].values.astype(np.float64),
                'low': ohlcv_df['low'].values.astype(np.float64)
            }
    
    # ğŸ”¥ ê°„ë‹¨í•œ ì²­í¬ ìƒì„±
    print("3. ì²­í¬ ìƒì„± ì¤‘...")
    all_chunks = []
    
    for tf, group in signals_df.groupby('timeframe'):
        if tf not in ohlcv_data:
            continue
            
        # ğŸ”¥ ê°„ë‹¨í•œ ì²­í¬ í¬ê¸° ê²°ì •
        chunk_size = 20000 if len(group) > 100000 else 10000
        
        # ì²­í¬ ë¶„í• 
        for i in range(0, len(group), chunk_size):
            chunk = group.iloc[i:i+chunk_size]
            ohlcv = ohlcv_data[tf]
            chunk_args = (i//chunk_size, tf, chunk, 
                         ohlcv['timestamps'], ohlcv['high'], ohlcv['low'])
            all_chunks.append(chunk_args)
    
    print(f"   ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
    
    # ğŸ”¥ ìµœëŒ€ ë³‘ë ¬ ì²˜ë¦¬
    print("4. ë³‘ë ¬ ë¶„ì„ ì‹œì‘...")
    results = []
    
    # ğŸ”¥ ì›Œì»¤ ìˆ˜ ëŒ€í­ ì¦ê°€
    max_workers = min(os.cpu_count() * 2, 32)  # CPU ì½”ì–´ ìˆ˜ x 2
    print(f"   ì›Œì»¤ ìˆ˜: {max_workers}")
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_chunk, chunk_args) for chunk_args in all_chunks]
        
        for future in tqdm(as_completed(futures), total=len(futures), desc="ë³‘ë ¬ ë¶„ì„"):
            try:
                result = future.result()
                if result is not None:
                    results.append(result)
            except Exception:
                continue
    
    # ê²°ê³¼ ì •ë¦¬
    print("5. ê²°ê³¼ ì •ë¦¬...")
    if results:
        final_df = pd.concat(results, ignore_index=True)
        final_df['signal_type'] = final_df['label_type'].map({1: 'Buy', -1: 'Sell'})
        final_df.to_csv(output_file, index=False)
        
        print(f"âœ… ì™„ë£Œ: {len(final_df):,}ê°œ ê²°ê³¼")
        print(f"í‰ê·  ìˆ˜ìµë¥ : {final_df['profit_pct'].mean():.2f}%")
    else:
        print("âŒ ê²°ê³¼ ì—†ìŒ")

if __name__ == "__main__":
    main()