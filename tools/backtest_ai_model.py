import torch
import pandas as pd
from pathlib import Path
import sys
import numpy as np
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[1]
sys.path.append(str(project_root))

def setup_cuda_optimization():
    """CUDA ìµœì í™” ì„¤ì •"""
    if torch.cuda.is_available():
        print(f"ğŸ”¥ CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
        print(f"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.cuda.empty_cache()
        
        return True
    else:
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€ëŠ¥ - CPU ëª¨ë“œ")
        return False

# === ğŸ”¥ ì •í™•í•œ ëª¨ë¸ êµ¬ì¡° (í•™ìŠµëœ ëª¨ë¸ê³¼ ë™ì¼) ===
class ExactTradingTransformer(torch.nn.Module):
    """í•™ìŠµëœ ëª¨ë¸ê³¼ ì •í™•íˆ ë™ì¼í•œ êµ¬ì¡°"""
    
    def __init__(self, input_dim=8, d_model=64, nhead=4, num_encoder_layers=2, 
                 dim_feedforward=256, num_classes=2, dropout=0.1):
        super().__init__()
        
        self.input_projection = torch.nn.Linear(input_dim, d_model)
        self.positional_encoding = torch.nn.Parameter(torch.randn(500, d_model))
        
        encoder_layer = torch.nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=True
        )
        
        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)
        
        # ğŸ”¥ í•™ìŠµëœ ëª¨ë¸ê³¼ ì •í™•íˆ ë™ì¼í•œ ì¶œë ¥ í—¤ë“œ
        self.signal_head = torch.nn.Sequential(
            torch.nn.Linear(d_model, d_model // 2),
            torch.nn.ReLU(),
            torch.nn.Dropout(dropout),
            torch.nn.Linear(d_model // 2, num_classes)
        )
        
        self.dropout = torch.nn.Dropout(dropout)
        
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        
        # Input projection
        x = self.input_projection(x)
        
        # Positional encoding
        pos_enc = self.positional_encoding[:seq_len, :].unsqueeze(0)
        x = x + pos_enc
        
        # Transformer
        x = self.transformer_encoder(x)
        
        # Pooling
        x = x.mean(dim=1)
        x = self.dropout(x)
        
        # ğŸ”¥ ì‹ í˜¸ ì˜ˆì¸¡ë§Œ (í•™ìŠµëœ ëª¨ë¸ê³¼ ë™ì¼)
        signal_pred = self.signal_head(x)
        
        return signal_pred

def diagnose_labeling_vs_ai():
    """
    ğŸ” ë¼ë²¨ë§ vs AI ì˜ˆì¸¡ ì§„ë‹¨ ë„êµ¬
    """
    # --- CUDA ì„¤ì • ---
    cuda_available = setup_cuda_optimization()
    device = torch.device("cuda" if cuda_available else "cpu")
    
    # --- ê²½ë¡œ ì„¤ì • ---
    model_path = project_root / "models" / "pytorch26_transformer_v1.pth"
    sequences_dir = project_root / "data" / "sequences_macd" / "test"
    output_dir = project_root / "results" / "diagnosis"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ” ë¼ë²¨ë§ vs AI ì˜ˆì¸¡ ì§„ë‹¨ ì‹œì‘!")
    print("=" * 60)
    
    # --- 1. ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¶„ì„ ---
    print("\nğŸ“Š Step 1: ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¶„ì„")
    try:
        merged_labels_path = project_root / "data" / "processed" / "btc_usdt_kst" / "labeled" / "merged_all_labels.parquet"
        
        if merged_labels_path.exists():
            merged_labels = pd.read_parquet(merged_labels_path)
            print(f"âœ… ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¡œë“œ: {len(merged_labels):,}í–‰")
            
            # ì›ë³¸ ë¼ë²¨ ë¶„í¬
            original_label_dist = merged_labels['label'].value_counts().sort_index()
            print(f"\nğŸ“ˆ ì›ë³¸ ë¼ë²¨ ë¶„í¬:")
            for label, count in original_label_dist.items():
                pct = count / len(merged_labels) * 100
                label_name = {-1: "ë§¤ë„", 0: "ê´€ë§", 1: "ë§¤ìˆ˜"}.get(label, f"ê¸°íƒ€({label})")
                print(f"   {label_name}({label}): {count:,}ê°œ ({pct:.2f}%)")
        else:
            print(f"âŒ ì›ë³¸ ë¼ë²¨ë§ íŒŒì¼ ì—†ìŒ: {merged_labels_path}")
            return
            
    except Exception as e:
        print(f"âŒ ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
        return
    
    # --- 2. ì‹œí€€ìŠ¤ ë°ì´í„° ë¼ë²¨ ë¶„í¬ ì²´í¬ ---
    print(f"\nğŸ“ Step 2: ì‹œí€€ìŠ¤ ë°ì´í„° ë¼ë²¨ ë¶„í¬ ì²´í¬")
    try:
        # ì‹œí€€ìŠ¤ íŒŒì¼ë“¤ ìŠ¤ìº”
        available_files = list(sequences_dir.glob("*.pt"))
        if not available_files:
            print(f"âŒ ì‹œí€€ìŠ¤ ë°ì´í„° ì—†ìŒ: {sequences_dir}")
            return
        
        print(f"âœ… ì‹œí€€ìŠ¤ íŒŒì¼ ë°œê²¬: {len(available_files):,}ê°œ")
        
        # ìƒ˜í”Œë§í•´ì„œ ë¼ë²¨ ë¶„í¬ í™•ì¸ (1000ê°œ ìƒ˜í”Œ)
        sample_size = min(1000, len(available_files))
        sample_files = np.random.choice(available_files, sample_size, replace=False)
        
        sequence_labels = []
        print(f"ğŸ“Š {sample_size}ê°œ íŒŒì¼ì—ì„œ ë¼ë²¨ ìƒ˜í”Œë§ ì¤‘...")
        
        for file in tqdm(sample_files, desc="ë¼ë²¨ ì¶”ì¶œ"):
            try:
                data = torch.load(file, map_location='cpu', weights_only=False)
                original_label = data['label']
                
                # ë³€í™˜ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜
                if original_label == -1:
                    converted_label = 0  # ë§¤ë„ â†’ 0
                elif original_label == 1:
                    converted_label = 1  # ë§¤ìˆ˜ â†’ 1
                else:
                    converted_label = 0  # ê´€ë§ â†’ 0
                
                sequence_labels.append({
                    'file': file.name,
                    'original_label': int(original_label),
                    'converted_label': converted_label
                })
                
            except Exception:
                print(f"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file.name}")
        
        # ì‹œí€€ìŠ¤ ë¼ë²¨ ë¶„í¬ ë¶„ì„
        sequence_df = pd.DataFrame(sequence_labels)
        
        print(f"\nğŸ“ˆ ì‹œí€€ìŠ¤ ì›ë³¸ ë¼ë²¨ ë¶„í¬ (ë³€í™˜ ì „):")
        orig_dist = sequence_df['original_label'].value_counts().sort_index()
        for label, count in orig_dist.items():
            pct = count / len(sequence_df) * 100
            label_name = {-1: "ë§¤ë„", 0: "ê´€ë§", 1: "ë§¤ìˆ˜"}.get(label, f"ê¸°íƒ€({label})")
            print(f"   {label_name}({label}): {count}ê°œ ({pct:.2f}%)")
        
        print(f"\nğŸ”„ ì‹œí€€ìŠ¤ ë³€í™˜ í›„ ë¼ë²¨ ë¶„í¬:")
        conv_dist = sequence_df['converted_label'].value_counts().sort_index()
        for label, count in conv_dist.items():
            pct = count / len(sequence_df) * 100
            label_name = {0: "ê´€ë§/ë§¤ë„", 1: "ë§¤ìˆ˜"}.get(label, f"ê¸°íƒ€({label})")
            print(f"   {label_name}({label}): {count}ê°œ ({pct:.2f}%)")
        
        # ğŸš¨ í•µì‹¬ ë¬¸ì œ ì§„ë‹¨
        buy_ratio_original = len(merged_labels[merged_labels['label'] == 1]) / len(merged_labels) * 100
        buy_ratio_sequence = len(sequence_df[sequence_df['converted_label'] == 1]) / len(sequence_df) * 100
        
        print(f"\nğŸš¨ í•µì‹¬ ë¬¸ì œ ì§„ë‹¨:")
        print(f"   ì›ë³¸ ë§¤ìˆ˜ ë¼ë²¨ ë¹„ìœ¨: {buy_ratio_original:.2f}%")
        print(f"   ì‹œí€€ìŠ¤ ë§¤ìˆ˜ ë¼ë²¨ ë¹„ìœ¨: {buy_ratio_sequence:.2f}%")
        
        if buy_ratio_sequence < 1.0:
            print(f"   âŒ ì‹œí€€ìŠ¤ì—ì„œ ë§¤ìˆ˜ ë¼ë²¨ì´ ì‹¬ê°í•˜ê²Œ ë¶€ì¡±í•¨!")
        elif buy_ratio_sequence < buy_ratio_original * 0.5:
            print(f"   âš ï¸ ì‹œí€€ìŠ¤ì—ì„œ ë§¤ìˆ˜ ë¼ë²¨ì´ ì›ë³¸ ëŒ€ë¹„ ë§ì´ ê°ì†Œí•¨")
        else:
            print(f"   âœ… ì‹œí€€ìŠ¤ ë§¤ìˆ˜ ë¼ë²¨ ë¹„ìœ¨ ì •ìƒ")
            
    except Exception as e:
        print(f"âŒ ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
        return
    
    # --- 3. AI ëª¨ë¸ ì˜ˆì¸¡ ë¶„ì„ ---
    print(f"\nğŸ¤– Step 3: AI ëª¨ë¸ ì˜ˆì¸¡ ë¶„ì„")
    try:
        # ëª¨ë¸ ë¡œë“œ
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        model_config = checkpoint.get('config', {})
        
        model = ExactTradingTransformer(
            input_dim=model_config.get('input_dim', 8),
            d_model=model_config.get('d_model', 64)
        )
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        model_state = checkpoint['model_state_dict']
        filtered_state = {k: v for k, v in model_state.items() 
                         if not (k.startswith('return_head') or k.startswith('confidence_head'))}
        
        model.load_state_dict(filtered_state, strict=False)
        model.to(device)
        model.eval()
        
        print(f"âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í•™ìŠµ ì •í™•ë„: {checkpoint.get('val_acc', 0):.4f})")
        
        # ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰
        sample_predictions = []
        test_files = np.random.choice(available_files, min(500, len(available_files)), replace=False)
        
        print(f"ğŸ”® {len(test_files)}ê°œ ìƒ˜í”Œë¡œ AI ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸...")
        
        with torch.no_grad():
            for file in tqdm(test_files, desc="AI ì˜ˆì¸¡"):
                try:
                    data = torch.load(file, map_location='cpu', weights_only=False)
                    features = data['features'].unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                    original_label = int(data['label'])
                    
                    # ë¼ë²¨ ë³€í™˜
                    true_label = 1 if original_label == 1 else 0
                    
                    # AI ì˜ˆì¸¡
                    signal_pred = model(features)
                    probabilities = torch.softmax(signal_pred, dim=1)[0].cpu().numpy()
                    predicted_label = int(torch.argmax(signal_pred, dim=1).cpu().numpy()[0])
                    
                    sample_predictions.append({
                        'file': file.name,
                        'original_label': original_label,
                        'true_label': true_label,
                        'predicted_label': predicted_label,
                        'prob_sell': probabilities[0],
                        'prob_buy': probabilities[1],
                        'correct': int(true_label == predicted_label)
                    })
                    
                except Exception:
                    continue
        
        # AI ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
        pred_df = pd.DataFrame(sample_predictions)
        
        print(f"\nğŸ¯ AI ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„:")
        print(f"   ì´ ì˜ˆì¸¡ ìƒ˜í”Œ: {len(pred_df)}ê°œ")
        print(f"   ì „ì²´ ì •í™•ë„: {pred_df['correct'].mean():.4f} ({pred_df['correct'].mean()*100:.2f}%)")
        
        # ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬
        ai_pred_dist = pred_df['predicted_label'].value_counts().sort_index()
        print(f"\nğŸ¤– AI ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬:")
        for label, count in ai_pred_dist.items():
            pct = count / len(pred_df) * 100
            label_name = {0: "ê´€ë§/ë§¤ë„", 1: "ë§¤ìˆ˜"}.get(label, f"ê¸°íƒ€({label})")
            print(f"   {label_name}({label}): {count}ê°œ ({pct:.2f}%)")
        
        # ì‹¤ì œ ë¼ë²¨ ë¶„í¬
        true_dist = pred_df['true_label'].value_counts().sort_index()
        print(f"\nğŸ“Š ì‹¤ì œ ë¼ë²¨ ë¶„í¬:")
        for label, count in true_dist.items():
            pct = count / len(pred_df) * 100
            label_name = {0: "ê´€ë§/ë§¤ë„", 1: "ë§¤ìˆ˜"}.get(label, f"ê¸°íƒ€({label})")
            print(f"   {label_name}({label}): {count}ê°œ ({pct:.2f}%)")
        
        # ë§¤ìˆ˜ í™•ë¥  ë¶„í¬
        buy_prob_stats = pred_df['prob_buy'].describe()
        print(f"\nğŸ“ˆ ë§¤ìˆ˜ í™•ë¥  í†µê³„:")
        print(f"   í‰ê· : {buy_prob_stats['mean']:.4f}")
        print(f"   ì¤‘ê°„ê°’: {buy_prob_stats['50%']:.4f}")
        print(f"   ìµœëŒ€ê°’: {buy_prob_stats['max']:.4f}")
        print(f"   í‘œì¤€í¸ì°¨: {buy_prob_stats['std']:.4f}")
        
        # ë‹¤ì–‘í•œ ì„ê³„ê°’ì—ì„œì˜ ë§¤ìˆ˜ ì‹ í˜¸
        print(f"\nğŸšï¸ ì„ê³„ê°’ë³„ ë§¤ìˆ˜ ì‹ í˜¸ ìˆ˜:")
        for threshold in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
            buy_signals = (pred_df['prob_buy'] > threshold).sum()
            pct = buy_signals / len(pred_df) * 100
            print(f"   ì„ê³„ê°’ {threshold}: {buy_signals}ê°œ ({pct:.2f}%)")
        
        # ê²°ê³¼ ì €ì¥
        pred_df.to_csv(output_dir / "ai_prediction_analysis.csv", index=False)
        sequence_df.to_csv(output_dir / "sequence_label_analysis.csv", index=False)
        
    except Exception as e:
        print(f"âŒ AI ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return
    
    # --- 4. ìµœì¢… ì§„ë‹¨ ê²°ê³¼ ---
    print(f"\n" + "="*60)
    print(f"ğŸ” ìµœì¢… ì§„ë‹¨ ê²°ê³¼")
    print(f"="*60)
    
    # ë§¤ìˆ˜ ë¼ë²¨ ì¶”ì 
    original_buy_count = len(merged_labels[merged_labels['label'] == 1])
    sequence_buy_count = len(sequence_df[sequence_df['converted_label'] == 1])
    ai_buy_predictions = len(pred_df[pred_df['predicted_label'] == 1])
    ai_high_prob_buy = len(pred_df[pred_df['prob_buy'] > 0.5])
    
    print(f"\nğŸ“ˆ ë§¤ìˆ˜ ë¼ë²¨ ì¶”ì :")
    print(f"   1ï¸âƒ£ ì›ë³¸ ë¼ë²¨ë§: {original_buy_count:,}ê°œ ë§¤ìˆ˜ ë¼ë²¨")
    print(f"   2ï¸âƒ£ ì‹œí€€ìŠ¤ ë³€í™˜: {sequence_buy_count}ê°œ ë§¤ìˆ˜ ë¼ë²¨ (ìƒ˜í”Œ ê¸°ì¤€)")
    print(f"   3ï¸âƒ£ AI ì˜ˆì¸¡: {ai_buy_predictions}ê°œ ë§¤ìˆ˜ ì˜ˆì¸¡")
    print(f"   4ï¸âƒ£ AI ê³ í™•ë¥ : {ai_high_prob_buy}ê°œ (í™•ë¥  50% ì´ìƒ)")
    
    # ë¬¸ì œ ì§„ë‹¨
    problems = []
    if sequence_buy_count == 0:
        problems.append("ğŸš¨ ì‹œí€€ìŠ¤ ë°ì´í„°ì— ë§¤ìˆ˜ ë¼ë²¨ì´ ì—†ìŒ - ì‹œí€€ìŠ¤ ìƒì„± ê³¼ì • ë¬¸ì œ")
    if ai_buy_predictions == 0:
        problems.append("ğŸš¨ AIê°€ ë§¤ìˆ˜ ì˜ˆì¸¡ì„ ì „í˜€ í•˜ì§€ ì•ŠìŒ - ëª¨ë¸ í•™ìŠµ ë¬¸ì œ")
    if pred_df['prob_buy'].max() < 0.7:
        problems.append("âš ï¸ AI ë§¤ìˆ˜ í™•ë¥ ì´ ì „ë°˜ì ìœ¼ë¡œ ë‚®ìŒ - ëª¨ë¸ ë³´ìˆ˜ì  ì„±í–¥")
    
    if problems:
        print(f"\nâŒ ë°œê²¬ëœ ë¬¸ì œë“¤:")
        for i, problem in enumerate(problems, 1):
            print(f"   {i}. {problem}")
    else:
        print(f"\nâœ… íŠ¹ë³„í•œ ë¬¸ì œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # í•´ê²°ì±… ì œì•ˆ
    print(f"\nğŸ’¡ í•´ê²°ì±… ì œì•ˆ:")
    if sequence_buy_count == 0:
        print(f"   1. generate_sequences.pyì—ì„œ ë§¤ìˆ˜ ë¼ë²¨ ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •")
        print(f"   2. ì „ì²´ ë°ì´í„°ì—ì„œ ë§¤ìˆ˜ ë¼ë²¨ ì˜ì—­ ìš°ì„  ì„ íƒ")
    
    if ai_buy_predictions == 0:
        print(f"   3. ëª¨ë¸ ì¬í•™ìŠµì‹œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©")
        print(f"   4. ì„ê³„ê°’ì„ 0.3-0.4ë¡œ ë‚®ì¶°ì„œ ë§¤ìˆ˜ ì‹ í˜¸ ì¦ê°€")
    
    print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼ëŠ” ë‹¤ìŒ íŒŒì¼ì—ì„œ í™•ì¸:")
    print(f"   - {output_dir / 'ai_prediction_analysis.csv'}")
    print(f"   - {output_dir / 'sequence_label_analysis.csv'}")

if __name__ == "__main__":
    diagnose_labeling_vs_ai()
