import pandas as pd
from pathlib import Path
from tqdm import tqdm
import re

def merge_and_sort_labels():
    """
    data/processed/btc_usdt_kst/labeled/ í´ë”ì˜ ëª¨ë“  ë¼ë²¨ parquet íŒŒì¼ì„
    í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë³‘í•©í•˜ê³  íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
    """
    # ğŸ”¥ ê²½ë¡œ ìˆ˜ì • - ì‹¤ì œ ë¼ë²¨ ìƒì„± ê²½ë¡œì™€ ì¼ì¹˜
    input_dir = Path('data/processed/btc_usdt_kst/labeled')
    output_dir = Path('data/processed/btc_usdt_kst/labeled')
    output_file = output_dir / 'merged_all_labels.parquet'
    
    print(f"ğŸ“ ì…ë ¥ ê²½ë¡œ: {input_dir}")
    print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {output_file}")
    
    # ğŸ”¥ ì‹¤ì œ íŒŒì¼ íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì •
    label_files = list(input_dir.glob('*_macd_labeled.parquet'))
    
    # ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ í™•ì¸
    all_files = list(input_dir.glob('*.parquet'))
    print(f"ğŸ“‚ ì „ì²´ íŒŒì¼ ìˆ˜: {len(all_files)}ê°œ")
    if all_files:
        print("ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ë“¤:")
        for file in sorted(all_files):
            print(f"  - {file.name}")
    
    if not label_files:
        print(f"âŒ '{input_dir}' ë””ë ‰í† ë¦¬ì—ì„œ ë¼ë²¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ” '*_macd_labeled.parquet' íŒ¨í„´ì˜ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    print(f"\nğŸ”„ ì´ {len(label_files)}ê°œì˜ ë¼ë²¨ íŒŒì¼ì„ ë³‘í•©í•©ë‹ˆë‹¤.")

    all_labels_df_list = []
    successful_files = 0
    failed_files = 0
    
    for file in tqdm(label_files, desc="ğŸ“Š ë¼ë²¨ íŒŒì¼ ì²˜ë¦¬ì¤‘"):
        try:
            # ğŸ”¥ íŒŒì¼ëª…ì—ì„œ íƒ€ì„í”„ë ˆì„ ì¶”ì¶œ (ìˆ˜ì •ëœ íŒ¨í„´)
            match = re.search(r'(.+)_macd_labeled\.parquet', file.name)
            if not match:
                print(f"âš ï¸ íŒŒì¼ëª… íŒ¨í„´ ë¶ˆì¼ì¹˜, ê±´ë„ˆë›°ê¸°: {file.name}")
                failed_files += 1
                continue
                
            timeframe = match.group(1)
            print(f"ğŸ“ˆ ì²˜ë¦¬ì¤‘: {timeframe}")

            df = pd.read_parquet(file)
            
            # ê¸°ë³¸ ë°ì´í„° ê²€ì¦
            if df.empty:
                print(f"âš ï¸ '{file.name}': ë¹ˆ ë°ì´í„°í”„ë ˆì„, ê±´ë„ˆë›°ê¸°")
                failed_files += 1
                continue
            
            # ì‹œê°„ëŒ€ ì •ë³´ í†µì¼ (timezone-naiveë¡œ ë³€í™˜)
            if hasattr(df.index, 'tz') and df.index.tz is not None:
                df.index = df.index.tz_localize(None)
                print(f"  ğŸ”§ ì‹œê°„ëŒ€ ì •ë³´ ì œê±°: {timeframe}")

            # ì¸ë±ìŠ¤ íƒ€ì… í™•ì¸
            if not isinstance(df.index, pd.DatetimeIndex):
                print(f"âŒ '{file.name}': ì¸ë±ìŠ¤ê°€ DatetimeIndexê°€ ì•„ë‹˜ ({type(df.index)})")
                
                # ğŸ”§ ìë™ ë³µêµ¬ ì‹œë„
                try:
                    if 'timestamp' in df.columns:
                        df.index = pd.to_datetime(df.columns['timestamp'])
                        df = df.drop('timestamp', axis=1)
                    else:
                        df.index = pd.to_datetime(df.index)
                    print(f"  âœ… ì¸ë±ìŠ¤ ë³µêµ¬ ì„±ê³µ: {timeframe}")
                except Exception as e:
                    print(f"  âŒ ì¸ë±ìŠ¤ ë³µêµ¬ ì‹¤íŒ¨: {e}")
                    failed_files += 1
                    continue

            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            if 'label' not in df.columns:
                print(f"âš ï¸ '{file.name}': 'label' ì»¬ëŸ¼ ì—†ìŒ")
                failed_files += 1
                continue
            
            # ë¼ë²¨ ë¶„í¬ í™•ì¸
            label_counts = df['label'].value_counts().sort_index()
            non_zero_labels = df[df['label'] != 0]
            
            print(f"  ğŸ“Š {timeframe} ë¼ë²¨ ë¶„í¬: {dict(label_counts)}")
            print(f"  ğŸ¯ ì‹ í˜¸ ë¼ë²¨: {len(non_zero_labels):,}ê°œ")
            
            # íƒ€ì„í”„ë ˆì„ ì •ë³´ ì¶”ê°€
            df_copy = df.copy()
            df_copy['timeframe'] = timeframe
            df_copy['file_source'] = file.name
            
            all_labels_df_list.append(df_copy)
            successful_files += 1

        except Exception as e:
            print(f"âŒ '{file.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            failed_files += 1

    # ê²°ê³¼ í™•ì¸
    print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
    print(f"  âœ… ì„±ê³µ: {successful_files}ê°œ")
    print(f"  âŒ ì‹¤íŒ¨: {failed_files}ê°œ")
    
    if not all_labels_df_list:
        print("âŒ ì²˜ë¦¬í•  ë¼ë²¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ğŸ”„ ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    print("\nğŸ”„ ë°ì´í„°í”„ë ˆì„ ë³‘í•© ì¤‘...")
    merged_df = pd.concat(all_labels_df_list, ignore_index=False)
    
    # ì¸ë±ìŠ¤ ì´ë¦„ ì„¤ì • (ì—†ëŠ” ê²½ìš°)
    if merged_df.index.name is None:
        merged_df.index.name = 'timestamp'
    
    # ì¤‘ë³µ ì œê±° (ê°™ì€ ì‹œê°„, ê°™ì€ íƒ€ì„í”„ë ˆì„)
    print("ğŸ”„ ì¤‘ë³µ ë°ì´í„° ì œê±° ì¤‘...")
    before_dedup = len(merged_df)
    merged_df = merged_df.reset_index()
    merged_df = merged_df.drop_duplicates(subset=[merged_df.columns[0], 'timeframe'], keep='first')
    after_dedup = len(merged_df)
    
    print(f"  ğŸ“Š ì¤‘ë³µ ì œê±°: {before_dedup:,} â†’ {after_dedup:,} (ì œê±°: {before_dedup-after_dedup:,}ê°œ)")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ ì •ë ¬
    print("ğŸ”„ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ ì •ë ¬ ì¤‘...")
    timestamp_col = merged_df.columns[0]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ íƒ€ì„ìŠ¤íƒ¬í”„
    merged_df = merged_df.sort_values([timestamp_col, 'timeframe'])
    
    # ğŸ“Š ìµœì¢… í†µê³„
    total_labels = len(merged_df)
    signal_labels = len(merged_df[merged_df['label'] != 0])
    
    print("\n" + "="*60)
    print("ğŸ‰ ë¼ë²¨ ë³‘í•© ì™„ë£Œ!")
    print("="*60)
    print(f"ğŸ“Š ì´ ë¼ë²¨ ìˆ˜: {total_labels:,}ê°œ")
    print(f"ğŸ¯ ì‹ í˜¸ ë¼ë²¨: {signal_labels:,}ê°œ ({signal_labels/total_labels*100:.1f}%)")
    print(f"ğŸ“ˆ íƒ€ì„í”„ë ˆì„ ìˆ˜: {merged_df['timeframe'].nunique()}ê°œ")
    
    # íƒ€ì„í”„ë ˆì„ë³„ í†µê³„
    print("\nğŸ“Š íƒ€ì„í”„ë ˆì„ë³„ ë¼ë²¨ ìˆ˜:")
    tf_stats = merged_df['timeframe'].value_counts().sort_index()
    for tf, count in tf_stats.items():
        print(f"  {tf}: {count:,}ê°œ")
    
    # ğŸ“ ê²°ê³¼ ì €ì¥
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # Parquet ì €ì¥
    merged_df.to_parquet(output_file, index=False)
    print(f"  âœ… Parquet: {output_file}")
    
    # CSV ì €ì¥ (ì„ íƒì )
    csv_output_file = output_dir / 'merged_all_labels.csv'
    merged_df.to_csv(csv_output_file, index=False, encoding='utf-8-sig')
    print(f"  âœ… CSV: {csv_output_file}")
    
    # ğŸ“‹ ë¯¸ë¦¬ë³´ê¸°
    print(f"\nğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
    print("ì²« 5í–‰:")
    print(merged_df.head())
    print("\në§ˆì§€ë§‰ 5í–‰:")
    print(merged_df.tail())
    
    return output_file

if __name__ == "__main__":
    print("ğŸš€ MACD ë¼ë²¨ ë³‘í•© ì‹œì‘")
    print("="*60)
    
    result_file = merge_and_sort_labels()
    
    if result_file:
        print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: Phase 2.5 ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!")
        print(f"ğŸ“ ë³‘í•©ëœ ë¼ë²¨ íŒŒì¼: {result_file}")
    
    print("\nğŸ ë¼ë²¨ ë³‘í•© ì™„ë£Œ!")