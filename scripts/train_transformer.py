import torch
import torch.nn as nn
import torch.optim as optim
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
import time
import sys
from tqdm import tqdm

# ğŸ”¥ PyTorch 2.6 í˜¸í™˜ì„± ì„¤ì •
if __name__ == '__main__':
    torch.multiprocessing.set_start_method('spawn', force=True)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

def setup_cuda_optimization():
    """CUDA í™˜ê²½ ìµœì í™”"""
    if torch.cuda.is_available():
        print(f"ğŸ”¥ GPU: {torch.cuda.get_device_name()}")
        print(f"   CUDA: {torch.version.cuda}, ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB") # type: ignore
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.cuda.empty_cache()
        return True
    return False

# === ğŸ”¥ ê°œì„ ëœ ë°ì´í„°ì…‹ (ë¼ë²¨ ë¶ˆê· í˜• í•´ê²°) ===
class BalancedTradingDataset(torch.utils.data.Dataset):
    """ë¼ë²¨ ê· í˜• ë§ì¶˜ íŠ¸ë ˆì´ë”© ë°ì´í„°ì…‹"""
    
    def __init__(self, data_dir, max_samples=None, balance_ratio=0.3):
        self.data_dir = Path(data_dir)
        self.balance_ratio = balance_ratio  # ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ ë¹„ìœ¨
        
        # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° ë¼ë²¨ë³„ ë¶„ë¥˜
        self.buy_files = []
        self.sell_files = []
        self.hold_files = []
        
        if self.data_dir.exists():
            print(f"ğŸ“‚ ë°ì´í„° ë””ë ‰í† ë¦¬ ìŠ¤ìº”: {self.data_dir}")
            for file in self.data_dir.iterdir():
                if file.suffix == '.pt':
                    try:
                        # ë¹ ë¥¸ ë¼ë²¨ í™•ì¸ (ë©”íƒ€ë°ì´í„°ë§Œ)
                        data = torch.load(file, map_location='cpu', weights_only=False)
                        label = data.get('label', 0)
                        
                        if label == 1:  # ë§¤ìˆ˜
                            self.buy_files.append(str(file))
                        elif label == -1:  # ë§¤ë„
                            self.sell_files.append(str(file))
                        else:  # ê´€ë§
                            self.hold_files.append(str(file))
                            
                    except Exception:
                        continue
        
        print(f"ğŸ“Š ë¼ë²¨ ë¶„í¬ - ë§¤ìˆ˜: {len(self.buy_files)}, ë§¤ë„: {len(self.sell_files)}, ê´€ë§: {len(self.hold_files)}")
        
        # ğŸ”¥ ë¼ë²¨ ê· í˜• ë§ì¶”ê¸°
        self.balanced_files = self._balance_dataset()
        
        # ìƒ˜í”Œ ì œí•œ
        if max_samples and len(self.balanced_files) > max_samples:
            self.balanced_files = self.balanced_files[:max_samples]
        
        print(f"âœ… ê· í˜• ë§ì¶˜ ë°ì´í„°: {len(self.balanced_files)}ê°œ")
    
    def _balance_dataset(self):
        """ë°ì´í„°ì…‹ ê· í˜• ë§ì¶”ê¸°"""
        # ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ ê°œìˆ˜ ê²°ì •
        signal_count = min(len(self.buy_files), len(self.sell_files))
        target_signal_count = int(signal_count * 2)  # ë§¤ìˆ˜ + ë§¤ë„
        
        # ê´€ë§ ì‹ í˜¸ ê°œìˆ˜ (ì „ì²´ì˜ 60-70% ì •ë„)
        target_hold_count = int(target_signal_count * 2)
        
        balanced_files = []
        
        # ë§¤ìˆ˜ ì‹ í˜¸ ì¶”ê°€
        if self.buy_files:
            count = min(target_signal_count // 2, len(self.buy_files))
            balanced_files.extend(self.buy_files[:count])
        
        # ë§¤ë„ ì‹ í˜¸ ì¶”ê°€
        if self.sell_files:
            count = min(target_signal_count // 2, len(self.sell_files))
            balanced_files.extend(self.sell_files[:count])
        
        # ê´€ë§ ì‹ í˜¸ ì¶”ê°€
        if self.hold_files:
            count = min(target_hold_count, len(self.hold_files))
            balanced_files.extend(self.hold_files[:count])
        
        return balanced_files
    
    def __len__(self):
        return len(self.balanced_files)
    
    def __getitem__(self, idx):
        try:
            data = torch.load(self.balanced_files[idx], map_location='cpu', weights_only=False)
            features = data['features']
            label = data['label']
            
            # ğŸ”¥ 3í´ë˜ìŠ¤ ë¼ë²¨ë§ (ë§¤ë„/ê´€ë§/ë§¤ìˆ˜)
            if label == -1:      # ë§¤ë„
                label_tensor = torch.tensor(0, dtype=torch.long)
            elif label == 0:     # ê´€ë§
                label_tensor = torch.tensor(1, dtype=torch.long)
            else:                # ë§¤ìˆ˜ (label == 1)
                label_tensor = torch.tensor(2, dtype=torch.long)
            
            return features, label_tensor
        
        except Exception:
            # ì—ëŸ¬ ì‹œ ê´€ë§ ë¼ë²¨ë¡œ ë°˜í™˜
            return torch.randn(240, 8), torch.tensor(1, dtype=torch.long)

# === ğŸš€ ê°œì„ ëœ íŠ¸ëœìŠ¤í¬ë¨¸ (ì‹ í˜¸ ê°ì§€ íŠ¹í™”) ===
class TradingSignalTransformer(nn.Module):
    """íŠ¸ë ˆì´ë”© ì‹ í˜¸ ê°ì§€ íŠ¹í™” íŠ¸ëœìŠ¤í¬ë¨¸"""
    
    def __init__(self, input_dim, d_model=128, nhead=8, num_encoder_layers=4, 
                 dim_feedforward=512, num_classes=3, dropout=0.1):
        super().__init__()
        
        # ì…ë ¥ ì „ì²˜ë¦¬
        self.input_projection = nn.Sequential(
            nn.Linear(input_dim, d_model),
            nn.LayerNorm(d_model),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.positional_encoding = nn.Parameter(torch.randn(1000, d_model) * 0.1)
        
        # íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=True,
            activation='gelu'  # GELU í™œì„±í™” í•¨ìˆ˜
        )
        
        self.transformer_encoder = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=num_encoder_layers
        )
        
        # ğŸ”¥ ë‹¤ì¤‘ í’€ë§ ì „ëµ
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        self.max_pool = nn.AdaptiveMaxPool1d(1)
        
        # ğŸ”¥ ì‹ í˜¸ ê°ì§€ í—¤ë“œ (ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬)
        self.signal_head = nn.Sequential(
            nn.Linear(d_model * 2, d_model),  # avg + max pooling
            nn.LayerNorm(d_model),
            nn.GELU(),
            nn.Dropout(dropout),
            
            nn.Linear(d_model, d_model // 2),
            nn.LayerNorm(d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            
            nn.Linear(d_model // 2, num_classes)
        )
        
        # ğŸ”¥ ì‹ ë¢°ë„ í—¤ë“œ ì¶”ê°€
        self.confidence_head = nn.Sequential(
            nn.Linear(d_model * 2, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, 1),
            nn.Sigmoid()  # 0-1 ì‹ ë¢°ë„
        )
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        
        # ì…ë ¥ íˆ¬ì˜
        x = self.input_projection(x)
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        pos_enc = self.positional_encoding[:seq_len, :].unsqueeze(0)
        x = x + pos_enc
        
        # íŠ¸ëœìŠ¤í¬ë¨¸
        x = self.transformer_encoder(x)  # [batch, seq, d_model]
        
        # ğŸ”¥ ë‹¤ì¤‘ í’€ë§
        x_transposed = x.transpose(1, 2)  # [batch, d_model, seq]
        avg_pooled = self.global_pool(x_transposed).squeeze(-1)  # [batch, d_model]
        max_pooled = self.max_pool(x_transposed).squeeze(-1)     # [batch, d_model]
        
        # í’€ë§ ê²°í•©
        combined = torch.cat([avg_pooled, max_pooled], dim=1)  # [batch, d_model*2]
        combined = self.dropout(combined)
        
        # ì¶œë ¥
        signal_pred = self.signal_head(combined)
        confidence = self.confidence_head(combined)
        
        return signal_pred, confidence

# === ğŸ”¥ ê°œì„ ëœ í›ˆë ¨ í•¨ìˆ˜ ===
def run_training_epoch(model, loader, optimizer, device, epoch_num, total_epochs):
    """í›ˆë ¨ ì—í¬í¬"""
    model.train()
    total_loss, total_correct, total_samples = 0, 0, 0
    
    # ğŸ”¥ ê°€ì¤‘ ì†ì‹¤ í•¨ìˆ˜ (í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°)
    class_weights = torch.tensor([2.0, 1.0, 2.0]).to(device)  # [ë§¤ë„, ê´€ë§, ë§¤ìˆ˜]
    loss_fn = nn.CrossEntropyLoss(weight=class_weights)
    confidence_loss_fn = nn.MSELoss()
    
    progress_bar = tqdm(loader, desc=f"Train Epoch {epoch_num}/{total_epochs}")
    
    for features, signal_target in progress_bar:
        features = features.to(device, non_blocking=True)
        signal_target = signal_target.to(device, non_blocking=True)
        
        optimizer.zero_grad()
        
        # Forward pass
        signal_pred, confidence = model(features)
        
        # ğŸ”¥ ë³µí•© ì†ì‹¤ í•¨ìˆ˜
        signal_loss = loss_fn(signal_pred, signal_target)
        
        # ì‹ ë¢°ë„ ëª©í‘œ (ì •ë‹µ ì˜ˆì¸¡ì‹œ ë†’ì€ ì‹ ë¢°ë„)
        preds = torch.argmax(signal_pred, dim=1)
        confidence_target = (preds == signal_target).float().unsqueeze(1)
        confidence_loss = confidence_loss_fn(confidence, confidence_target)
        
        total_loss_value = signal_loss + 0.1 * confidence_loss
        
        # Backward pass
        total_loss_value.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        # í†µê³„
        total_loss += total_loss_value.item() * features.size(0)
        total_correct += (preds == signal_target).sum().item()
        total_samples += features.size(0)
        
        # ğŸ”¥ ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ ê°œìˆ˜ ì¶”ì 
        buy_signals = (preds == 2).sum().item()
        sell_signals = (preds == 0).sum().item()
        
        progress_bar.set_postfix(
            loss=f"{total_loss/total_samples:.4f}",
            acc=f"{total_correct/total_samples:.3f}",
            buy=buy_signals,
            sell=sell_signals
        )
    
    return total_loss / total_samples, total_correct / total_samples

def run_validation_epoch(model, loader, device, epoch_num, total_epochs):
    """ê²€ì¦ ì—í¬í¬"""
    model.eval()
    total_loss, total_correct, total_samples = 0, 0, 0
    all_confidences = []
    signal_counts = [0, 0, 0]  # [ë§¤ë„, ê´€ë§, ë§¤ìˆ˜]
    
    class_weights = torch.tensor([2.0, 1.0, 2.0]).to(device)
    loss_fn = nn.CrossEntropyLoss(weight=class_weights)
    
    progress_bar = tqdm(loader, desc=f"Val Epoch {epoch_num}/{total_epochs}")
    
    with torch.no_grad():
        for features, signal_target in progress_bar:
            features = features.to(device, non_blocking=True)
            signal_target = signal_target.to(device, non_blocking=True)
            
            signal_pred, confidence = model(features)
            loss = loss_fn(signal_pred, signal_target)
            
            total_loss += loss.item() * features.size(0)
            
            preds = torch.argmax(signal_pred, dim=1)
            total_correct += (preds == signal_target).sum().item()
            total_samples += features.size(0)
            
            # ì‹ í˜¸ ì¹´ìš´íŠ¸
            for i in range(3):
                signal_counts[i] += int((preds == i).sum().item())
            
            all_confidences.extend(confidence.cpu().numpy())
            
            progress_bar.set_postfix(
                loss=f"{total_loss/total_samples:.4f}",
                acc=f"{total_correct/total_samples:.3f}",
                conf=f"{np.mean(all_confidences):.3f}"
            )
    
    # ğŸ”¥ ìƒì„¸ í†µê³„ ì¶œë ¥
    print(f"   ğŸ“Š ì‹ í˜¸ ë¶„í¬ - ë§¤ë„: {signal_counts[0]}, ê´€ë§: {signal_counts[1]}, ë§¤ìˆ˜: {signal_counts[2]}")
    print(f"   ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {np.mean(all_confidences):.3f}")
    
    return total_loss / total_samples, total_correct / total_samples

# === ğŸ”¥ ì„¤ì • í´ë˜ìŠ¤ ê°œì„  ===
class ImprovedConfig:
    MODEL_DIR = project_root / "models"
    MODEL_NAME = "improved_trading_transformer_v2.pth"
    
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    EPOCHS = 20  # ë” ë§ì€ ì—í¬í¬
    BATCH_SIZE = 32
    LEARNING_RATE = 2e-4
    NUM_WORKERS = 4 if torch.cuda.is_available() else 0
    
    # ë” í° ëª¨ë¸ (ì„±ëŠ¥ ìš°ì„ )
    D_MODEL = 128
    N_HEAD = 8
    NUM_ENCODER_LAYERS = 4
    DIM_FEEDFORWARD = 512
    DROPOUT = 0.1
    NUM_CLASSES = 3  # ë§¤ë„/ê´€ë§/ë§¤ìˆ˜

def create_improved_dataloaders(batch_size=32, num_workers=4):
    """ê°œì„ ëœ ë°ì´í„°ë¡œë”"""
    from torch.utils.data import DataLoader
    
    sequence_dir = project_root / 'data' / 'sequences_macd'
    dataloaders = {}
    
    # ğŸ”¥ ë” ë§ì€ ìƒ˜í”Œ ì‚¬ìš©
    max_samples = {
        'train': 20000,   # ëŠ˜ë¦¼
        'val': 5000,      
        'test': 2000      
    }
    
    for split in ['train', 'val', 'test']:
        data_path = sequence_dir / split
        if data_path.exists():
            dataset = BalancedTradingDataset(
                data_path, 
                max_samples=max_samples[split]
            )
            
            dataloaders[split] = DataLoader(
                dataset, 
                batch_size=batch_size,
                shuffle=(split == 'train'),
                num_workers=num_workers,
                pin_memory=torch.cuda.is_available(),
                drop_last=True,
                persistent_workers=(num_workers > 0)
            )
            print(f"âœ… {split} ë¡œë”: {len(dataset)}ê°œ ìƒ˜í”Œ")
    
    return dataloaders

def main():
    """ê°œì„ ëœ ë©”ì¸ í•¨ìˆ˜"""
    
    setup_cuda_optimization()
    config = ImprovedConfig()
    config.MODEL_DIR.mkdir(parents=True, exist_ok=True)
    
    print("ğŸš€ ê°œì„ ëœ íŠ¸ë ˆì´ë”© íŠ¸ëœìŠ¤í¬ë¨¸ í•™ìŠµ!")
    print(f"Device: {config.DEVICE}, Batch: {config.BATCH_SIZE}, Epochs: {config.EPOCHS}")
    
    # ğŸ”¥ ê°œì„ ëœ ë°ì´í„°ë¡œë”
    print("\nğŸ“Š ê· í˜• ë§ì¶˜ ë°ì´í„°ë¡œë” ìƒì„±...")
    try:
        dataloaders = create_improved_dataloaders(
            batch_size=config.BATCH_SIZE, 
            num_workers=config.NUM_WORKERS
        )
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return
    
    # ì…ë ¥ ì°¨ì› í™•ì¸
    print("\nğŸ” ì…ë ¥ ì°¨ì› í™•ì¸...")
    try:
        sample_files = list(Path(project_root / 'data' / 'sequences_macd' / 'train').glob('*.pt'))
        if sample_files:
            sample_data = torch.load(sample_files[0], weights_only=False)
            input_dim = sample_data['features'].shape[1]
            print(f"âœ… ì…ë ¥ ì°¨ì›: {input_dim}")
        else:
            raise FileNotFoundError("ìƒ˜í”Œ íŒŒì¼ ì—†ìŒ")
    except Exception as e:
        print(f"âŒ ì°¨ì› í™•ì¸ ì‹¤íŒ¨: {e}")
        input_dim = 8
    
    # ğŸ”¥ ê°œì„ ëœ ëª¨ë¸
    print("\nğŸ¤– ê°œì„ ëœ ëª¨ë¸ ì´ˆê¸°í™”...")
    model = TradingSignalTransformer(
        input_dim=input_dim,
        d_model=config.D_MODEL,
        nhead=config.N_HEAD,
        num_encoder_layers=config.NUM_ENCODER_LAYERS,
        dim_feedforward=config.DIM_FEEDFORWARD,
        num_classes=config.NUM_CLASSES,
        dropout=config.DROPOUT
    ).to(config.DEVICE)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š ëª¨ë¸: {total_params:,}ê°œ íŒŒë¼ë¯¸í„°")
    
    # ğŸ”¥ ê°œì„ ëœ ì˜µí‹°ë§ˆì´ì € (í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€)
    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.EPOCHS)
    
    # í•™ìŠµ ë£¨í”„
    print("\nğŸš€ ê°œì„ ëœ í•™ìŠµ ì‹œì‘!")
    best_val_acc = 0.0
    start_time = time.time()
    
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    
    for epoch in range(config.EPOCHS):
        # í›ˆë ¨
        train_loss, train_acc = run_training_epoch(
            model, dataloaders['train'], optimizer, config.DEVICE, epoch + 1, config.EPOCHS
        )
        
        # ê²€ì¦
        val_loss, val_acc = run_validation_epoch(
            model, dataloaders['val'], config.DEVICE, epoch + 1, config.EPOCHS
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        # ê¸°ë¡
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        
        print(f"\nEpoch {epoch+1}/{config.EPOCHS}")
        print(f"  Train: Loss {train_loss:.4f}, Acc {train_acc:.4f}")
        print(f"  Val:   Loss {val_loss:.4f}, Acc {val_acc:.4f}")
        print(f"  LR: {scheduler.get_last_lr()[0]:.6f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'train_losses': train_losses,
                'val_losses': val_losses,
                'train_accs': train_accs,
                'val_accs': val_accs,
                'config': {
                    'input_dim': input_dim,
                    'd_model': config.D_MODEL,
                    'num_classes': config.NUM_CLASSES
                }
            }, config.MODEL_DIR / config.MODEL_NAME)
            print(f"  âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! (ì •í™•ë„: {val_acc:.4f})")
    
    # ğŸ”¥ í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.title('Loss History')
    plt.legend()
    
    plt.subplot(1, 3, 2)
    plt.plot(train_accs, label='Train Acc')
    plt.plot(val_accs, label='Val Acc')
    plt.title('Accuracy History')
    plt.legend()
    
    plt.subplot(1, 3, 3)
    plt.plot([scheduler.get_last_lr()[0]] * len(train_losses))
    plt.title('Learning Rate')
    
    plt.tight_layout()
    plt.savefig(config.MODEL_DIR / 'training_history.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    total_time = time.time() - start_time
    print(f"\nğŸ‰ ê°œì„ ëœ í•™ìŠµ ì™„ë£Œ!")
    print(f"â° ì‹œê°„: {total_time/60:.1f}ë¶„")
    print(f"ğŸ¯ ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}")
    print(f"ğŸ“ ëª¨ë¸: {config.MODEL_DIR / config.MODEL_NAME}")

if __name__ == '__main__':
    main()
