import random
import sys
from pathlib import Path
from typing import TypedDict

from typing_extensions import override

import numpy as np
import pandas as pd
import torch
from torch import nn
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root: Path = Path(__file__).resolve().parents[1]
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# --- TypedDicts for static analysis ---

class PTData(TypedDict):
    """ .pt íŒŒì¼ì— ì €ì¥ëœ ë°ì´í„° êµ¬ì¡° """
    features: torch.Tensor
    label: torch.Tensor

class SequenceLabel(TypedDict):
    """ ë¼ë²¨ ì¶”ì¶œ ê²°ê³¼ë¥¼ ìœ„í•œ êµ¬ì¡° """
    file: str
    original_label: int
    converted_label: int

class Prediction(TypedDict):
    """ AI ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìœ„í•œ êµ¬ì¡° """
    file: str
    original_label: int
    true_label: int
    predicted_label: int
    prob_sell: float
    prob_buy: float
    correct: int

class ModelConfig(TypedDict, total=False):
    """ ëª¨ë¸ ì„¤ì • ì¼ë¶€ """
    input_dim: int
    d_model: int
    nhead: int
    num_encoder_layers: int
    dim_feedforward: int
    dropout: float

class Checkpoint(TypedDict):
    """ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° """
    config: ModelConfig
    model_state_dict: dict[str, torch.Tensor]
    val_acc: float


def setup_cuda_optimization() -> bool:
    """CUDA ìµœì í™” ì„¤ì •"""
    if torch.cuda.is_available():
        print(f"ğŸ”¥ CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
        print(f"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB") # type: ignore
        torch.backends.cudnn.benchmark = True
        return True
    else:
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€ëŠ¥ - CPU ëª¨ë“œ")
        return False

class ExactTradingTransformer(nn.Module):
    """í•™ìŠµëœ ëª¨ë¸ê³¼ ì •í™•íˆ ë™ì¼í•œ êµ¬ì¡°"""
    
    input_projection: nn.Linear
    positional_encoding: nn.Parameter
    transformer_encoder: nn.TransformerEncoder
    signal_head: nn.Sequential
    dropout: nn.Dropout

    def __init__(self, input_dim: int = 8, d_model: int = 64, nhead: int = 4, 
                 num_encoder_layers: int = 2, dim_feedforward: int = 256, 
                 num_classes: int = 2, dropout: float = 0.1):
        super().__init__()
        
        self.input_projection = nn.Linear(input_dim, d_model)
        self.positional_encoding = nn.Parameter(torch.randn(500, d_model))
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,
            dropout=dropout, batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)
        
        self.signal_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, num_classes)
        )
        self.dropout = nn.Dropout(dropout)
        
    @override
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        _, seq_len, _ = x.shape
        
        # 'x'ë¥¼ ì¬í• ë‹¹í•˜ëŠ” ëŒ€ì‹ , 'h' (hidden) ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° íë¦„ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.
        h = self.input_projection(x)
        pos_enc = self.positional_encoding[:seq_len, :].unsqueeze(0)
        h = h + pos_enc
        h = self.transformer_encoder(h)
        h = h.mean(dim=1)
        h = self.dropout(h)
        signal_pred = self.signal_head(h)
        return signal_pred

def diagnose_labeling_vs_ai() -> None:
    """ğŸ” ë¼ë²¨ë§ vs AI ì˜ˆì¸¡ ì§„ë‹¨ ë„êµ¬"""
    cuda_available = setup_cuda_optimization()
    device = torch.device("cuda" if cuda_available else "cpu")
    
    model_path = project_root / "models" / "pytorch26_transformer_v1.pth"
    sequences_dir = project_root / "data" / "sequences_macd" / "test"
    output_dir = project_root / "results" / "diagnosis"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    
    # 1. ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¶„ì„
    print("\nğŸ“Š Step 1: ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¶„ì„")
    merged_labels_path = project_root / "data" / "processed" / "btc_usdt_kst" / "labeled" / "merged_all_labels.parquet"
    if not merged_labels_path.exists():
        print(f"âŒ ì›ë³¸ ë¼ë²¨ë§ íŒŒì¼ ì—†ìŒ: {merged_labels_path}")
        return
        
    merged_labels: pd.DataFrame = pd.read_parquet(merged_labels_path)
    print(f"âœ… ì›ë³¸ ë¼ë²¨ë§ ë°ì´í„° ë¡œë“œ: {len(merged_labels):,}í–‰")
    original_label_dist = merged_labels['label'].value_counts().sort_index() # type: ignore
    for label, count in original_label_dist.items():
        print(f"   Label {label}: {count:,} ({count / len(merged_labels) * 100:.2f}%)")
    
    # 2. ì‹œí€€ìŠ¤ ë°ì´í„° ë¼ë²¨ ë¶„í¬ ì²´í¬
    print(f"\nğŸ“ Step 2: ì‹œí€€ìŠ¤ ë°ì´í„° ë¼ë²¨ ë¶„í¬ ì²´í¬")
    available_files: list[Path] = list(sequences_dir.glob("*.pt"))
    if not available_files:
        print(f"âŒ ì‹œí€€ìŠ¤ ë°ì´í„° ì—†ìŒ: {sequences_dir}")
        return

    sample_size = min(1000, len(available_files))
    # np.random.choiceëŠ” íƒ€ì… ì •ë³´ë¥¼ ìƒê²Œ í•˜ë¯€ë¡œ, random.sampleì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    sample_files = random.sample(available_files, sample_size)
    sequence_labels: list[SequenceLabel] = []
    
    for file_path in tqdm(sample_files, desc="ë¼ë²¨ ì¶”ì¶œ"):
        try:
            # .get() ëŒ€ì‹  ì§ì ‘ ì ‘ê·¼í•˜ê³ , isinstance ì²´í¬ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
            # TypedDictì— ë”°ë¼ 'label' í‚¤ëŠ” í•­ìƒ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.
            loaded_sequence_data: PTData = torch.load(file_path, map_location='cpu') # type: ignore
            original_label_tensor = loaded_sequence_data['label']
            original_label = int(original_label_tensor.item())
            
            sequence_labels.append({
                'file': file_path.name,
                'original_label': original_label,
                'converted_label': 1 if original_label == 1 else 0
            })
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path.name}, ì˜¤ë¥˜: {e}")

    sequence_df = pd.DataFrame(sequence_labels)
    if not sequence_df.empty:
        print(f"\nğŸ”„ ì‹œí€€ìŠ¤ ë³€í™˜ í›„ ë¼ë²¨ ë¶„í¬:")
        print(sequence_df['converted_label'].value_counts(normalize=True).sort_index()) # type: ignore
    
    # 3. AI ëª¨ë¸ ì˜ˆì¸¡ ë¶„ì„
    print(f"\nğŸ¤– Step 3: AI ëª¨ë¸ ì˜ˆì¸¡ ë¶„ì„")
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        return

    checkpoint: Checkpoint = torch.load(model_path, map_location=device) # type: ignore
    model_config_dict = checkpoint.get('config', {})
    
    model = ExactTradingTransformer(
        input_dim=model_config_dict.get('input_dim', 8),
        d_model=model_config_dict.get('d_model', 64)
    )
    
    model_state = checkpoint.get('model_state_dict', {})
    filtered_state = {k: v for k, v in model_state.items() if not k.startswith(('return_head', 'confidence_head'))}
    _ = model.load_state_dict(filtered_state, strict=False)
    _ = model.to(device)
    _ = model.eval()
    
    print(f"âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í•™ìŠµ ì •í™•ë„: {checkpoint.get('val_acc', 0):.4f})")
    
    sample_predictions: list[Prediction] = []
    test_files_paths = random.sample(available_files, min(500, len(available_files)))
    
    with torch.no_grad():
        for file_path in tqdm(test_files_paths, desc="AI ì˜ˆì¸¡"):
            try:
                loaded_test_data: PTData = torch.load(file_path, map_location='cpu') # type: ignore
                features: torch.Tensor = loaded_test_data['features'].unsqueeze(0).to(device)
                original_label = int(loaded_test_data['label'].item())
                true_label = 1 if original_label == 1 else 0
                
                signal_pred = model(features)
                probabilities = torch.softmax(signal_pred, dim=1).cpu().numpy()[0]
                predicted_label = int(torch.argmax(signal_pred, dim=1).item())
                
                sample_predictions.append({
                    'file': file_path.name, 'original_label': original_label, 'true_label': true_label,
                    'predicted_label': predicted_label, 'prob_sell': probabilities[0],
                    'prob_buy': probabilities[1], 'correct': int(true_label == predicted_label)
                })
            except Exception as e:
                print(f"âš ï¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {file_path.name}, ì˜¤ë¥˜: {e}")

    if not sample_predictions:
        print("âŒ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ")
        return
        
    pred_df = pd.DataFrame(sample_predictions)
    accuracy = pred_df['correct'].mean()
    print(f"\nğŸ“ˆ AI ì˜ˆì¸¡ ì •í™•ë„ (ìƒ˜í”Œ): {accuracy:.2%}")
    
    # ê²°ê³¼ ì €ì¥
    output_path = output_dir / "ai_vs_labeling_diagnosis.parquet"
    pred_df.to_parquet(output_path, index=False)
    print(f"\nğŸ’¾ ì§„ë‹¨ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    diagnose_labeling_vs_ai()
